{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer_version3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP44vVS8Im9FomKjVxdFz7e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5esfNv9WFeUy","executionInfo":{"status":"ok","timestamp":1622012906422,"user_tz":-540,"elapsed":3144,"user":{"displayName":"최검기","photoUrl":"","userId":"02132713927266936024"}},"outputId":"d1f3c92c-0b9c-4100-df1a-21903116a3a5"},"source":["!pip install tqdm"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tji1yT6qFmbe","executionInfo":{"status":"ok","timestamp":1622012921017,"user_tz":-540,"elapsed":14597,"user":{"displayName":"최검기","photoUrl":"","userId":"02132713927266936024"}},"outputId":"ca8f2054-2c5e-4a2a-d54a-fbf68da9721d"},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wdgeb2WYFmsV"},"source":["import torch\n","import torch.nn as nn\n","import json\n","from tqdm import tqdm\n","import numpy as np\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vLeNUSf8FofM"},"source":["\"\"\" configuration json을 읽어들이는 class \"\"\"\n","class Config(dict): \n","    __getattr__ = dict.__getitem__\n","    __setattr__ = dict.__setitem__\n","\n","    @classmethod\n","    def load(cls, file):\n","        with open(file, 'r') as f:\n","            config = json.loads(f.read())\n","            return Config(config)\n","\n","config = Config({\n","    \"n_input\": 200,\n","    \"n_enc_seq\": 200,\n","    \"n_dec_seq\": 200,\n","    \"n_layer\": 4,\n","    \"d_hidn\": 128,\n","    \"i_pad\": 0,\n","    \"d_ff\": 512,\n","    \"n_head\": 8,\n","    \"d_head\": 16,\n","    \"dropout\": 0.1,\n","    \"layer_norm_epsilon\": 1e-12\n","})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zar3BYoDGQjW"},"source":["\"\"\" sinusoid position encoding \"\"\"\n","def get_sinusoid_encoding_table(n_seq, d_hidn):\n","    def cal_angle(position, i_hidn):\n","        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n","    def get_posi_angle_vec(position):\n","        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n","\n","    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n","    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n","    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n","\n","    return sinusoid_table"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a8dr-vuYGrM9"},"source":["\"\"\" attention pad mask \"\"\"\n","def get_attn_pad_mask(seq_q, seq_k, i_pad):\n","    batch_size, len_q, _ = seq_q.size()\n","    batch_size, len_k, _ = seq_k.size()\n","    pad_attn_mask = seq_k[:, :, 0].data.eq(i_pad)\n","    pad_attn_mask= pad_attn_mask.unsqueeze(1).expand(batch_size, len_q, len_k)\n","    return pad_attn_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PWfXWHunGtUR"},"source":["\"\"\" attention decoder mask \"\"\"\n","def get_attn_decoder_mask(seq):\n","    subsequent_mask = torch.ones_like(seq[:,:,0]).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n","    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n","    return subsequent_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"syJf48P5GuZE"},"source":["\"\"\" scale dot product attention \"\"\"\n","class ScaledDotProductAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        self.dropout = nn.Dropout(config.dropout)\n","        self.scale = 1 / (self.config.d_head ** 0.5)\n","    \n","    def forward(self, Q, K, V, attn_mask):\n","        # (bs, n_head, n_q_seq, n_k_seq)\n","        scores = torch.matmul(Q, K.transpose(-1, -2))\n","        scores = scores.mul_(self.scale)\n","        scores.masked_fill_(attn_mask, -1e9)\n","        # (bs, n_head, n_q_seq, n_k_seq)\n","        attn_prob = nn.Softmax(dim=-1)(scores)\n","        attn_prob = self.dropout(attn_prob)\n","        # (bs, n_head, n_q_seq, d_v)\n","        context = torch.matmul(attn_prob, V)\n","        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n","        return context, attn_prob"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RMOa5gDsG2R9"},"source":["\"\"\" multi head attention \"\"\"\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n","        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n","        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n","        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n","        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n","        self.dropout = nn.Dropout(config.dropout)\n","    \n","    def forward(self, Q, K, V, attn_mask):\n","        batch_size = Q.size(0)\n","        # (bs, n_head, n_q_seq, d_head)\n","        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n","        # (bs, n_head, n_k_seq, d_head)\n","        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n","        # (bs, n_head, n_v_seq, d_head)\n","        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n","\n","        # (bs, n_head, n_q_seq, n_k_seq)\n","        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n","\n","        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n","        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n","        # (bs, n_head, n_q_seq, h_head * d_head)\n","        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n","        # (bs, n_head, n_q_seq, e_embd)\n","        output = self.linear(context)\n","        output = self.dropout(output)\n","        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n","        return output, attn_prob"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IrRhFzB6Jb0P"},"source":["\"\"\" feed forward \"\"\"\n","class PoswiseFeedForwardNet(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n","        self.active = F.gelu\n","        self.dropout = nn.Dropout(config.dropout)\n","\n","    def forward(self, inputs):\n","        # (bs, d_ff, n_seq)\n","        output = self.conv1(inputs.transpose(1, 2))\n","        output = self.active(output)\n","        # (bs, n_seq, d_hidn)\n","        output = self.conv2(output).transpose(1, 2)\n","        output = self.dropout(output)\n","        # (bs, n_seq, d_hidn)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K3NqNmhPJcTW"},"source":["\"\"\" encoder layer \"\"\"\n","class EncoderLayer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.self_attn = MultiHeadAttention(self.config)\n","        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n","        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","    \n","    def forward(self, inputs, attn_mask):\n","        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n","        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n","        att_outputs = self.layer_norm1(inputs + att_outputs)\n","        # (bs, n_enc_seq, d_hidn)\n","        ffn_outputs = self.pos_ffn(att_outputs)\n","        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n","        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n","        return ffn_outputs, attn_prob"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iq6dITnqJdn_"},"source":["\"\"\" encoder \"\"\"\n","class Encoder(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.projection = nn.Linear(2, self.config.d_hidn, bias=False)\n","        #self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidn)\n","        self.sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_enc_seq, self.config.d_hidn))\n","        #self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n","\n","        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n","    \n","    def forward(self, inputs):\n","\n","        x = self.projection(inputs.float())\n","\n","        #inputs *= torch.sqrt(self.config.d_hidn)\n","        x += self.sinusoid_table.to(config.device)\n","\n","        # (bs, n_enc_seq, n_enc_seq)\n","        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n","\n","        attn_probs = []\n","        for layer in self.layers:\n","            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n","            outputs, attn_prob = layer(x, attn_mask)\n","            attn_probs.append(attn_prob)\n","        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n","        return outputs, attn_probs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JkJEbS59Jer1"},"source":["\"\"\" decoder layer \"\"\"\n","class DecoderLayer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.self_attn = MultiHeadAttention(self.config)\n","        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","        self.dec_enc_attn = MultiHeadAttention(self.config)\n","        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n","        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","    \n","    def forward(self, dec_inputs, enc_outputs, self_attn_mask, dec_enc_attn_mask):\n","        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n","        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n","        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n","        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_enc_seq)\n","        dec_enc_att_outputs, dec_enc_attn_prob = self.dec_enc_attn(self_att_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n","        dec_enc_att_outputs = self.layer_norm2(self_att_outputs + dec_enc_att_outputs)\n","        # (bs, n_dec_seq, d_hidn)\n","        ffn_outputs = self.pos_ffn(dec_enc_att_outputs)\n","        ffn_outputs = self.layer_norm3(dec_enc_att_outputs + ffn_outputs)\n","        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n","        return ffn_outputs, self_attn_prob, dec_enc_attn_prob"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2knsUoxaJgSs"},"source":["\"\"\" decoder \"\"\"\n","class Decoder(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        self.projection = nn.Linear(2, self.config.d_hidn, bias=False)\n","       # self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n","        self.sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq, self.config.d_hidn))\n","      #  self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n","\n","        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n","    \n","    def forward(self, inputs, enc_inputs, enc_outputs):\n","\n","        x = self.projection(inputs.float())\n","        #x *= torch.sqrt(self.config.d_hidn)\n","        x += self.sinusoid_table.to(config.device)\n","\n","        # (bs, n_dec_seq, n_dec_seq)\n","        dec_attn_pad_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n","        # (bs, n_dec_seq, n_dec_seq)\n","        dec_attn_decoder_mask = get_attn_decoder_mask(inputs)\n","        # (bs, n_dec_seq, n_dec_seq)\n","        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n","        # (bs, n_dec_seq, n_enc_seq)\n","        dec_enc_attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n","\n","        self_attn_probs, dec_enc_attn_probs = [], []\n","        for layer in self.layers:\n","            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq), (bs, n_dec_seq, n_enc_seq)\n","            dec_outputs, self_attn_prob, dec_enc_attn_prob = layer(x, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n","            self_attn_probs.append(self_attn_prob)\n","            dec_enc_attn_probs.append(dec_enc_attn_prob)\n","        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)], [(bs, n_dec_seq, n_enc_seq)]S\n","\n","        return dec_outputs, self_attn_probs, dec_enc_attn_probs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lnFK1wIKJhay"},"source":["\"\"\" transformer \"\"\"\n","class Transformer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.encoder = Encoder(self.config)\n","    \n","    def forward(self, enc_inputs, dec_inputs):\n","\n","        enc_outputs, enc_self_attn_probs = self.encoder(enc_inputs)\n","\n","        dec_outputs, _ = torch.max(enc_outputs, dim=1)\n","\n","        return dec_outputs\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H9DzhWUAJqtA"},"source":["class ClassClassification(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.transformer = Transformer(self.config)\n","        self.projection = nn.Linear(self.config.d_hidn, self.config.n_output, bias=False)\n","\n","    def forward(self, enc_inputs, dec_inputs):\n","        # (bs, n_dec_seq, ), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n","\n","        dec_outputs = self.transformer(enc_inputs, dec_inputs)\n","\n","        # (bs, )\n","\n","       # dec_outputs, _ = torch.max(dec_outputs, dim=1)\n","\n","        # (bs, n_output)\n","\n","        logits = self.projection(dec_outputs)\n","\n","        # (bs, n_output), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n","        return logits\n","\n","\"\"\" 클래스 분류 데이터셋 \"\"\"\n","class ClassDataSet(torch.utils.data.Dataset):\n","    def __init__(self, np_Data):\n","        self.labels = torch.from_numpy(np_Data.item().get('set_of_labels')) # label load\n","\n","        temp_in = torch.from_numpy(np_Data.item().get('set_of_inputs'))\n","        temp_out = torch.from_numpy(np_Data.item().get('set_of_outputs'))\n","        \n","        self.data = torch.cat([temp_in, temp_out], dim = 2)\n","\n","\n","    def __len__(self):\n","        assert len(self.labels) == len(self.data)\n","        return len(self.labels)\n","    \n","    def __getitem__(self, i):\n","        return (torch.tensor(self.labels[i]),\n","                torch.tensor(self.data[i])\n","                )\n","\n","\"\"\" movie data collate_fn \"\"\"\n","def movie_collate_fn(inputs):\n","    labels, data = list(zip(*inputs))\n","\n","    data = torch.nn.utils.rnn.pad_sequence(data, batch_first=True, padding_value=0)\n","\n","    batch = [\n","        torch.stack(labels, dim=0),\n","        data\n","    ]\n","    return batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aH_pWYxaJ1ww"},"source":["# data loading\n","train_Data = np.load(\"/content/gdrive/My Drive/Colab Notebooks/Transformer/dataset_12_classes_1000_train.npy\", allow_pickle=True)\n","test_data = np.load(\"/content/gdrive/My Drive/Colab Notebooks/Transformer/dataset_12_classes_1000_test.npy\", allow_pickle=True)\n","batch_size = 128\n","train_dataset = ClassDataSet(train_Data)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=movie_collate_fn)\n","test_dataset = ClassDataSet(test_data)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=movie_collate_fn)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hWEa218sJ5Ji"},"source":["\"\"\" 모델 epoch 학습 \"\"\"\n","def train_epoch(config, epoch, model, criterion, optimizer, train_loader):\n","    losses = []\n","    model.train()\n","\n","    with tqdm(total=len(train_loader), desc=f\"Train {epoch}\") as pbar:\n","        for i, value in enumerate(train_loader):\n","            labels, datas = map(lambda v: v.to(config.device), value)\n","\n","            optimizer.zero_grad()\n","            outputs = model(datas, datas)\n","            logits = outputs\n","            \n","            loss = criterion(logits, labels)\n","            loss_val = loss.item()\n","            losses.append(loss_val)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            pbar.update(1)\n","            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n","    return np.mean(losses)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHhqZVMLh8cw"},"source":["\"\"\" 모델 epoch 평가 \"\"\"\n","def eval_epoch(config, model, data_loader):\n","    matchs = []\n","    model.eval()\n","\n","    n_word_total = 0\n","    n_correct_total = 0\n","    with tqdm(total=len(data_loader), desc=f\"Valid\") as pbar:\n","        for i, value in enumerate(data_loader):\n","            labels, datas = map(lambda v: v.to(config.device), value)\n","\n","            outputs = model(datas, datas)\n","            logits = outputs\n","            _, indices = logits.max(1)\n","\n","            match = torch.eq(indices, labels).detach()\n","            matchs.extend(match.cpu())\n","            accuracy = np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n","\n","            pbar.update(1)\n","            pbar.set_postfix_str(f\"Acc: {accuracy:.3f}\")\n","    return np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ketix6iSO1lS","executionInfo":{"status":"ok","timestamp":1622013631222,"user_tz":-540,"elapsed":3,"user":{"displayName":"최검기","photoUrl":"","userId":"02132713927266936024"}},"outputId":"0610d715-e50d-4d46-b7b9-c83e508049c4"},"source":["config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","config.n_output = 12\n","print(config)\n","\n","learning_rate = 1e-3\n","n_epoch = 10"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'n_input': 200, 'n_enc_seq': 200, 'n_dec_seq': 200, 'n_layer': 4, 'd_hidn': 128, 'i_pad': 0, 'd_ff': 512, 'n_head': 8, 'd_head': 16, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda'), 'n_output': 12}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-KHtKDeO6EU","executionInfo":{"status":"ok","timestamp":1622013821469,"user_tz":-540,"elapsed":189847,"user":{"displayName":"최검기","photoUrl":"","userId":"02132713927266936024"}},"outputId":"aad2b60d-1615-4e08-c367-31fcaffdaaa7"},"source":["torch.cuda.empty_cache()\n","model = ClassClassification(config).cuda()\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","losses, scores = [], []\n","for epoch in range(n_epoch):\n","    loss = train_epoch(config, epoch, model, criterion, optimizer, train_loader)\n","    score = eval_epoch(config, model, test_loader)\n","\n","    losses.append(loss)\n","    scores.append(score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train 0:   0%|          | 0/94 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","Train 0: 100%|██████████| 94/94 [00:10<00:00,  9.27it/s, Loss: 0.031 (0.440)]\n","Valid: 100%|██████████| 94/94 [00:08<00:00, 11.37it/s, Acc: 0.997]\n","Train 1: 100%|██████████| 94/94 [00:10<00:00,  9.23it/s, Loss: 0.033 (0.025)]\n","Valid: 100%|██████████| 94/94 [00:08<00:00, 11.33it/s, Acc: 0.995]\n","Train 2: 100%|██████████| 94/94 [00:10<00:00,  9.13it/s, Loss: 0.011 (0.014)]\n","Valid: 100%|██████████| 94/94 [00:08<00:00, 11.18it/s, Acc: 0.998]\n","Train 3: 100%|██████████| 94/94 [00:10<00:00,  9.05it/s, Loss: 0.028 (0.029)]\n","Valid: 100%|██████████| 94/94 [00:08<00:00, 11.16it/s, Acc: 0.997]\n","Train 4: 100%|██████████| 94/94 [00:10<00:00,  8.98it/s, Loss: 0.002 (0.006)]\n","Valid: 100%|██████████| 94/94 [00:08<00:00, 11.08it/s, Acc: 1.000]\n","Train 5: 100%|██████████| 94/94 [00:10<00:00,  8.92it/s, Loss: 0.010 (0.003)]\n","Valid: 100%|██████████| 94/94 [00:08<00:00, 11.08it/s, Acc: 0.988]\n","Train 6: 100%|██████████| 94/94 [00:10<00:00,  8.87it/s, Loss: 0.001 (0.003)]\n","Valid: 100%|██████████| 94/94 [00:08<00:00, 10.93it/s, Acc: 1.000]\n","Train 7: 100%|██████████| 94/94 [00:10<00:00,  8.82it/s, Loss: 0.000 (0.002)]\n","Valid: 100%|██████████| 94/94 [00:08<00:00, 10.90it/s, Acc: 1.000]\n","Train 8: 100%|██████████| 94/94 [00:10<00:00,  8.79it/s, Loss: 0.001 (0.002)]\n","Valid: 100%|██████████| 94/94 [00:08<00:00, 10.98it/s, Acc: 1.000]\n","Train 9: 100%|██████████| 94/94 [00:10<00:00,  8.75it/s, Loss: 0.001 (0.001)]\n","Valid: 100%|██████████| 94/94 [00:08<00:00, 10.94it/s, Acc: 1.000]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"49D835L5O-Q5","colab":{"base_uri":"https://localhost:8080/","height":621},"executionInfo":{"status":"ok","timestamp":1622013933920,"user_tz":-540,"elapsed":346,"user":{"displayName":"최검기","photoUrl":"","userId":"02132713927266936024"}},"outputId":"fa2b1a23-d755-48fa-d0bc-e1ba535c6035"},"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# table\n","data = {\n","    \"loss\": losses,\n","    \"score\": scores\n","}\n","df = pd.DataFrame(data)\n","display(df)\n","\n","# graph\n","plt.figure(figsize=[12, 4])\n","plt.plot(losses, label=\"loss\")\n","plt.plot(scores, label=\"score\")\n","plt.legend()\n","plt.xlabel('Epoch')\n","plt.ylabel('Value')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>loss</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.439602</td>\n","      <td>0.997000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.025385</td>\n","      <td>0.994833</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.014298</td>\n","      <td>0.997917</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.029274</td>\n","      <td>0.996500</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.006344</td>\n","      <td>0.999833</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.002771</td>\n","      <td>0.988000</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.003387</td>\n","      <td>0.999833</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.001598</td>\n","      <td>0.999750</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.001750</td>\n","      <td>0.999750</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.001153</td>\n","      <td>0.999917</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       loss     score\n","0  0.439602  0.997000\n","1  0.025385  0.994833\n","2  0.014298  0.997917\n","3  0.029274  0.996500\n","4  0.006344  0.999833\n","5  0.002771  0.988000\n","6  0.003387  0.999833\n","7  0.001598  0.999750\n","8  0.001750  0.999750\n","9  0.001153  0.999917"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"7EM5XBPrj0BD"},"source":[""],"execution_count":null,"outputs":[]}]}